{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 3001000\n",
      "__Number CUDA Devices: 1\n"
     ]
    }
   ],
   "source": [
    "environ[\"HIP_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    count = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Downloading shards: 100%|██████████| 2/2 [01:06<00:00, 33.45s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cuda\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a programmer that takes in sparse descriptions of a psychology experiment from a scientific paper and generates a PsychoPy Psyexp experiment file that can execute the described experiment.\"\n",
    "query = \"In this task participants are required to memorise and recall number series in order. Participants start out with three 3-digit sequences. If participants correctly recall 2 out of 3 three sequences, they progress to 4-digit sequence trials and so on. If participants respond incorrectly on 2/3 trials the experiment terminantes. This experiment is based on the original digit span experiment by Jacobs (1887).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": f\"{system_prompt}\\n Input: {query}\"}]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s><|user|> You are a programmer that takes in sparse descriptions of a psychology experiment from a scientific paper and generates a PsychoPy Psyexp experiment file that can execute the described experiment.\\n Input: In this task participants are required to memorise and recall number series in order. Participants start out with three 3-digit sequences. If participants correctly recall 2 out of 3 three sequences, they progress to 4-digit sequence trials and so on. If participants respond incorrectly on 2/3 trials the experiment terminantes. This experiment is based on the original digit span experiment by Jacobs (1887).<|end|><|assistant|> ```python\\n\\nfrom psychopy import visual, core, event\\n\\nfrom psychopy.tools.attributestack import AttributeStack\\n\\nfrom psychopy.tools.psytoolstub import PsyToolStub\\n\\n\\nclass DigitSpanExperiment(PsyToolStub):\\n\\n    def __init__(self, *args, **kwargs):\\n\\n        super().__init__(*args, **kwargs)\\n\\n        self.sequence_lengths = [3, 4, 5, 6]  # Extendable sequence lengths\\n\\n        self.max_trials = 10  # Maximum number of trials\\n\\n        self.sequence_count = 0  # Tracks the number of sequences presented\\n\\n        self.trial_count = 0  # Tracks the number of trials completed\\n\\n        self.correct_trials = 0  # Tracks the number of correctly recalled trials\\n\\n        self.sequence_display = visual.TextStim(win, text=\"\", pos=(0, 0), color=\\'white\\')\\n\\n\\n    def run_experiment(self):\\n\\n        while self.trial_count < self.max_trials:\\n\\n            sequence_length = self.sequence_lengths[self.sequence_count]\\n\\n            sequence = self.generate_sequence(sequence_length)\\n\\n            self.sequence_display.setText(sequence)\\n\\n            self.sequence_display.draw()\\n\\n            self.sequence_display.setPos(0, -self.height / 2)\\n\\n            self.sequence_display.draw(self.win)\\n\\n\\n            correct_responses = 0\\n\\n            for _ in range(sequence_length):\\n\\n                self.key_press = self.win.waitForEvent(event.KeyboardEvent)\\n\\n                if self.key_press.value == ord(sequence[self.sequence_count % sequence_length]):\\n\\n                    correct_responses += 1\\n\\n                self.sequence_count += 1\\n\\n\\n            if correct_responses >= 2 * (sequence_length // 2):\\n\\n                self.correct_trials += 1\\n\\n                self.sequence_lengths.append(sequence_length + 1)\\n\\n                self.sequence_count = 0\\n\\n                self.trial_count += 1\\n\\n                print(f\"Completed {self.correct_trials} trials with {correct_responses} correct responses.\")\\n\\n            else:\\n\\n                print(f\"Failed to complete the trial. Correct responses: {correct_responses}\")\\n\\n                break\\n\\n\\n    def generate_sequence(self, length):\\n\\n        import random\\n\\n        return \\'\\'.join(random.sample(\\'0123456789\\', length))\\n\\n\\n# Initialize and run the experiment\\n\\nwin = visual.Window([800, 600], fullscr=False)\\n\\nexperiment = DigitSpanExperiment(win=win)\\n\\nexperiment.run_experiment()\\n\\nwin.close()\\n\\n```\\n\\nThis code defines a `DigitSpanExperiment` class that extends `PsyToolStub` from PsychoPy. It initializes with a list of sequence lengths and a maximum number of trials. The `run_experiment` method generates sequences, displays them, and collects responses from the participant. It tracks the number of correctly recalled sequences and adjusts the sequence length accordingly, terminating the experiment if the participant fails to meet the criteria twice.<|end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(inputs, max_new_tokens=100_000)\n",
    "tokenizer.batch_decode(outputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
